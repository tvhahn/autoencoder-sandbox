{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Anomaly Detection\n",
    "Prototype an anomaly detection algorithm using autoencoders. Will be using fashion-MNIST data set. \"Hands-On Machine Learning\", by Aurelien Geron, is the basis for much of the code. https://github.com/ageron/handson-ml2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n",
      "Keras version:  2.2.4-tf\n",
      "Tensorboard version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorboard\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('TensorFlow version: ', tf.__version__)\n",
    "print('Keras version: ', keras.__version__)\n",
    "print('Tensorboard version:', tensorboard.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_all, y_train_all), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# shuffle the data, as a precaution\n",
    "X_train_all, y_train_all = shuffle(X_train_all, y_train_all, random_state=16)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=16)\n",
    "\n",
    "# convert all to dtype float32\n",
    "X_train_all = X_train_all.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (5000, 28, 28)\n",
      "y_val shape: (5000,)\n",
      "X_val_slim shape: (5000, 28, 28)\n",
      "y_val_slim shape: (5000,)\n",
      "X_train_slim shape: (50000, 28, 28)\n",
      "y_train_slim shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "# split the data between train and validation sets, and scale\n",
    "# also have a \"slimmed down\" data set that has only positive classes that will be used to train the autoencoder\n",
    "X_val, X_val_slim, X_train_slim = X_train_all[:5000] / 255.0, \\\n",
    "                                        X_train_all[5000:10000] / 255.0, \\\n",
    "                                        X_train_all[10000:] / 255.0\n",
    "y_val, y_val_slim, y_train_slim = y_train_all[:5000],y_train_all[5000:10000], y_train_all[10000:]\n",
    "\n",
    "# also scale the X_test\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('X_val_slim shape:', X_val_slim.shape)\n",
    "print('y_val_slim shape:', y_val_slim.shape)\n",
    "print('X_train_slim shape:', X_train_slim.shape)\n",
    "print('y_train_slim shape:', y_train_slim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_classes(class_to_remove, y_val_slim, X_val_slim):\n",
    "    \"\"\"Funciton to remove classes from train/val set\"\"\"\n",
    "    \n",
    "    # start with y_valid_slim\n",
    "    index_to_delete = []\n",
    "    for i, class_digit in enumerate(y_val_slim):\n",
    "        if class_digit in class_to_remove:\n",
    "            index_to_delete.append(i)\n",
    "\n",
    "    y_val_slim = np.delete(y_val_slim, index_to_delete)\n",
    "    X_val_slim = np.delete(X_val_slim, index_to_delete, axis=0)\n",
    "    \n",
    "    return X_val_slim, y_val_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (5000, 28, 28)\n",
      "y_val shape: (5000,)\n",
      "X_val_slim shape: (478, 28, 28)\n",
      "y_val_slim shape: (478,)\n",
      "X_train_slim shape: (5011, 28, 28)\n",
      "y_train_slim shape: (5011,)\n"
     ]
    }
   ],
   "source": [
    "# we will be training the autoencoder on the \"normal\" class only. All the rest will be labeled as \"anomalous\"\n",
    "# this is how anomaly detection is done in Chalapathy R, 2019 https://arxiv.org/pdf/1802.06360.pdf\n",
    "# I assume this is a good way to do it.... at least I can compare my results to theirs\n",
    "class_normal = 0\n",
    "class_to_remove = [i for i in range(0,10)]\n",
    "class_to_remove.remove(class_normal)\n",
    "class_to_remove = np.array(class_to_remove,dtype='uint8')\n",
    "\n",
    "\n",
    "X_val_slim, y_val_slim = remove_classes(class_to_remove, y_val_slim, X_val_slim)\n",
    "X_train_slim, y_train_slim = remove_classes(class_to_remove, y_train_slim, X_train_slim)\n",
    "\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('X_val_slim shape:', X_val_slim.shape)\n",
    "print('y_val_slim shape:', y_val_slim.shape)\n",
    "print('X_train_slim shape:', X_train_slim.shape)\n",
    "print('y_train_slim shape:', y_train_slim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for data prep\n",
    "class DataPrep:\n",
    "    def __init__(self, keras_dataset, class_normal, random_int=16, print_shapes=False):\n",
    "        \n",
    "        self.class_normal = class_normal\n",
    "        self.random_int = random_int\n",
    "        self.print_shapes = print_shapes\n",
    "\n",
    "        (X_train_all, y_train_all), (X_test, y_test) = keras_dataset.load_data()\n",
    "\n",
    "        # shuffle the data, as a precaution\n",
    "        self.X_train_all, self.y_train_all = shuffle(X_train_all, y_train_all, random_state=random_int)\n",
    "        self.X_test, self.y_test = shuffle(X_test, y_test, random_state=random_int)\n",
    "\n",
    "        # convert all to dtype float32\n",
    "        self.X_train_all = self.X_train_all.astype('float32')\n",
    "        self.X_test = self.X_test.astype('float32')\n",
    "\n",
    "    def remove_classes(self, X_val_slim, y_val_slim):\n",
    "        \"\"\"Funciton to remove classes from train/val set\"\"\"\n",
    "        \n",
    "        class_to_remove = [i for i in range(0,10)]\n",
    "        class_to_remove.remove(self.class_normal)\n",
    "        class_to_remove = np.array(class_to_remove,dtype='uint8')\n",
    "\n",
    "        # start with y_valid_slim\n",
    "        index_to_delete = []\n",
    "        for i, class_digit in enumerate(y_val_slim):\n",
    "            if class_digit in class_to_remove:\n",
    "                index_to_delete.append(i)\n",
    "\n",
    "        y_val_slim = np.delete(y_val_slim, index_to_delete)\n",
    "        X_val_slim = np.delete(X_val_slim, index_to_delete, axis=0)\n",
    "\n",
    "        return X_val_slim, y_val_slim\n",
    "        \n",
    "    def train_test_split(self):\n",
    "        # split the data between train and validation sets, and scale\n",
    "        # also have a \"slimmed down\" data set that has only positive classes that will be used to train the autoencoder\n",
    "        self.X_val, self.X_val_slim, self.X_train = self.X_train_all[:5000] / 255.0, \\\n",
    "                                                self.X_train_all[5000:10000] / 255.0, \\\n",
    "                                                self.X_train_all[10000:] / 255.0\n",
    "        self.y_val, self.y_val_slim, self.y_train = self.y_train_all[:5000],self.y_train_all[5000:10000], self.y_train_all[10000:]\n",
    "\n",
    "        # also scale the X_test\n",
    "        self.X_test = self.X_test / 255.0\n",
    "        \n",
    "        self.X_train_slim, self.y_train_slim = self.remove_classes(self.X_train, self.y_train)\n",
    "        self.X_val_slim, self.y_val_slim = self.remove_classes(self.X_val_slim, self.y_val_slim)\n",
    "        \n",
    "        if self.print_shapes == True:\n",
    "            print('X_val shape:', self.X_val.shape)\n",
    "            print('y_val shape:', self.y_val.shape)\n",
    "            print('X_val_slim shape:', self.X_val_slim.shape)\n",
    "            print('y_val_slim shape:', self.y_val_slim.shape)\n",
    "            print('X_train shape:', self.X_train.shape)\n",
    "            print('y_train shape:', self.y_train.shape)\n",
    "            print('X_train_slim shape:', self.X_train_slim.shape)\n",
    "            print('y_train_slim shape:', self.y_train_slim.shape)\n",
    "        \n",
    "        return (self.X_train, \n",
    "                self.y_train, \n",
    "                self.X_train_slim, \n",
    "                self.y_train_slim, \n",
    "                self.X_val,\n",
    "                self.y_val,\n",
    "                self.X_val_slim,\n",
    "                self.y_val_slim,\n",
    "                self.X_test,\n",
    "                self.y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (5000, 28, 28)\n",
      "y_val shape: (5000,)\n",
      "X_val_slim shape: (478, 28, 28)\n",
      "y_val_slim shape: (478,)\n",
      "X_train shape: (50000, 28, 28)\n",
      "y_train shape: (50000,)\n",
      "X_train_slim shape: (5011, 28, 28)\n",
      "y_train_slim shape: (5011,)\n"
     ]
    }
   ],
   "source": [
    "class_normal = 0\n",
    "\n",
    "# class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "data_model = DataPrep(fashion_mnist,class_normal)\n",
    "\n",
    "(X_train, y_train, \n",
    " X_train_slim, y_train_slim,\n",
    " X_val, y_val,\n",
    " X_val_slim, y_val_slim,\n",
    " X_test,y_test) = data_model.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Sparse Autoencoder\n",
    "\n",
    "We will build as sparse autoencoder. But first, we will build a vanilla stacked autoencoder as a comparison.\n",
    "\n",
    "Andrew Ng has a good video of what a sparse autoencoder is: https://youtu.be/vfnxKO2rMq4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we are using sigmoid activations so that the activations all end up between 0 and 1. This will make visualizing the activations easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "def plot_reconstructions(model, index_list, X_valid): \n",
    "    reconstructions = model.predict(X_valid)\n",
    "    \n",
    "    # get the length of index_list to set number of\n",
    "    # images to plot\n",
    "    n_images = len(index_list)\n",
    "\n",
    "    # Plot a random sample\n",
    "    fig, axes = plt.subplots(2, n_images,figsize=(n_images*1.5,3),dpi=150)\n",
    "    # fig.suptitle('Digits for Sample %i' %num, size=15, x=0.2)\n",
    "\n",
    "    for i in range(0, n_images):\n",
    "        axes[0][i].imshow(np.reshape(X_valid[index_list[i],:,:],[28,28]), cmap='Greys_r')\n",
    "        axes[0][i].axis('off')\n",
    "        axes[0][i].set_title(str(index_list[i]))\n",
    "        axes[1][i].imshow(np.reshape(reconstructions[index_list[i],:,:],[28,28]), cmap='Greys_r')\n",
    "        axes[1][i].axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see how the activations behave with this simple stacked autoencoder.\n",
    "- Using the validation data set, **what is the distribution of activations between 0 and 1?**\n",
    "- Using the validation data set, **what are the average neuron activation values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build custom regularizer for KL-Divergence\n",
    "K = keras.backend\n",
    "kl_divergence = keras.losses.kullback_leibler_divergence\n",
    "\n",
    "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, weight, target=0.1):\n",
    "        self.weight = weight\n",
    "        self.target = target\n",
    "    def __call__(self, inputs):\n",
    "        mean_activities = K.mean(inputs, axis=0)\n",
    "        return self.weight * (\n",
    "            kl_divergence(self.target, mean_activities) +\n",
    "            kl_divergence(1. - self.target, 1. - mean_activities))\n",
    "    \n",
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_kl_model(X_train_slim, X_val_slim, seed=42, epochs=500, earlystop_patience=8):\n",
    "\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
    "    sparse_kl_encoder = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(100, activation=\"selu\"),\n",
    "        keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n",
    "    ])\n",
    "    sparse_kl_decoder = keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
    "        keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "        keras.layers.Reshape([28, 28])\n",
    "    ])\n",
    "    sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n",
    "    sparse_kl_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=[rounded_accuracy])\n",
    "\n",
    "    # show summary, if wanted\n",
    "    # sparse_kl_encoder.summary()\n",
    "    # sparse_kl_decoder.summary()\n",
    "\n",
    "    # use tensorboard to track training\n",
    "    log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                          histogram_freq=0,\n",
    "                                                          update_freq='epoch',\n",
    "                                                          profile_batch=0)\n",
    "\n",
    "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=8, \n",
    "                                                          restore_best_weights=True)\n",
    "\n",
    "    history = sparse_kl_ae.fit(X_train_slim, X_train_slim, epochs=epochs,\n",
    "                               validation_data=[X_val_slim, X_val_slim], \n",
    "                               callbacks=[tensorboard_callback,earlystop_callback],verbose=0)\n",
    "    return sparse_kl_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5011 samples, validate on 478 samples\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b5b83c828>)\n",
      "Epoch 1/500\n",
      "5011/5011 [==============================] - 2s 306us/sample - loss: 0.4350 - rounded_accuracy: 0.8408 - val_loss: 0.3804 - val_rounded_accuracy: 0.8890\n",
      "Epoch 2/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3689 - rounded_accuracy: 0.8965 - val_loss: 0.3678 - val_rounded_accuracy: 0.8965\n",
      "Epoch 3/500\n",
      "5011/5011 [==============================] - 0s 94us/sample - loss: 0.3574 - rounded_accuracy: 0.9042 - val_loss: 0.3581 - val_rounded_accuracy: 0.9026\n",
      "Epoch 4/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3500 - rounded_accuracy: 0.9089 - val_loss: 0.3549 - val_rounded_accuracy: 0.9046\n",
      "Epoch 5/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3468 - rounded_accuracy: 0.9117 - val_loss: 0.3511 - val_rounded_accuracy: 0.9076\n",
      "Epoch 6/500\n",
      "5011/5011 [==============================] - 0s 94us/sample - loss: 0.3419 - rounded_accuracy: 0.9171 - val_loss: 0.3455 - val_rounded_accuracy: 0.9151\n",
      "Epoch 7/500\n",
      "5011/5011 [==============================] - 0s 94us/sample - loss: 0.3371 - rounded_accuracy: 0.9229 - val_loss: 0.3417 - val_rounded_accuracy: 0.9195\n",
      "Epoch 8/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3340 - rounded_accuracy: 0.9265 - val_loss: 0.3395 - val_rounded_accuracy: 0.9213\n",
      "Epoch 9/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3321 - rounded_accuracy: 0.9284 - val_loss: 0.3376 - val_rounded_accuracy: 0.9241\n",
      "Epoch 10/500\n",
      "5011/5011 [==============================] - 0s 97us/sample - loss: 0.3304 - rounded_accuracy: 0.9300 - val_loss: 0.3362 - val_rounded_accuracy: 0.9258\n",
      "Epoch 11/500\n",
      "5011/5011 [==============================] - 0s 98us/sample - loss: 0.3289 - rounded_accuracy: 0.9318 - val_loss: 0.3354 - val_rounded_accuracy: 0.9282\n",
      "Epoch 12/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3274 - rounded_accuracy: 0.9334 - val_loss: 0.3334 - val_rounded_accuracy: 0.9299\n",
      "Epoch 13/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3263 - rounded_accuracy: 0.9349 - val_loss: 0.3323 - val_rounded_accuracy: 0.9298\n",
      "Epoch 14/500\n",
      "5011/5011 [==============================] - 0s 97us/sample - loss: 0.3250 - rounded_accuracy: 0.9365 - val_loss: 0.3311 - val_rounded_accuracy: 0.9312\n",
      "Epoch 15/500\n",
      "5011/5011 [==============================] - 0s 99us/sample - loss: 0.3240 - rounded_accuracy: 0.9375 - val_loss: 0.3304 - val_rounded_accuracy: 0.9326\n",
      "Epoch 16/500\n",
      "5011/5011 [==============================] - 0s 97us/sample - loss: 0.3232 - rounded_accuracy: 0.9385 - val_loss: 0.3295 - val_rounded_accuracy: 0.9324\n",
      "Epoch 17/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3222 - rounded_accuracy: 0.9397 - val_loss: 0.3283 - val_rounded_accuracy: 0.9346\n",
      "Epoch 18/500\n",
      "5011/5011 [==============================] - 0s 98us/sample - loss: 0.3215 - rounded_accuracy: 0.9405 - val_loss: 0.3279 - val_rounded_accuracy: 0.9344\n",
      "Epoch 19/500\n",
      "5011/5011 [==============================] - 1s 100us/sample - loss: 0.3208 - rounded_accuracy: 0.9411 - val_loss: 0.3274 - val_rounded_accuracy: 0.9367\n",
      "Epoch 20/500\n",
      "5011/5011 [==============================] - 1s 102us/sample - loss: 0.3203 - rounded_accuracy: 0.9417 - val_loss: 0.3269 - val_rounded_accuracy: 0.9364\n",
      "Epoch 21/500\n",
      "5011/5011 [==============================] - 0s 94us/sample - loss: 0.3197 - rounded_accuracy: 0.9424 - val_loss: 0.3259 - val_rounded_accuracy: 0.9370\n",
      "Epoch 22/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3192 - rounded_accuracy: 0.9427 - val_loss: 0.3254 - val_rounded_accuracy: 0.9380\n",
      "Epoch 23/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3187 - rounded_accuracy: 0.9435 - val_loss: 0.3251 - val_rounded_accuracy: 0.9388\n",
      "Epoch 24/500\n",
      "5011/5011 [==============================] - 0s 94us/sample - loss: 0.3183 - rounded_accuracy: 0.9440 - val_loss: 0.3245 - val_rounded_accuracy: 0.9388\n",
      "Epoch 25/500\n",
      "5011/5011 [==============================] - 0s 97us/sample - loss: 0.3179 - rounded_accuracy: 0.9443 - val_loss: 0.3243 - val_rounded_accuracy: 0.9393\n",
      "Epoch 26/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3174 - rounded_accuracy: 0.9448 - val_loss: 0.3240 - val_rounded_accuracy: 0.9401\n",
      "Epoch 27/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3170 - rounded_accuracy: 0.9454 - val_loss: 0.3234 - val_rounded_accuracy: 0.9403\n",
      "Epoch 28/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3167 - rounded_accuracy: 0.9455 - val_loss: 0.3230 - val_rounded_accuracy: 0.9407\n",
      "Epoch 29/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3163 - rounded_accuracy: 0.9461 - val_loss: 0.3227 - val_rounded_accuracy: 0.9417\n",
      "Epoch 30/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3159 - rounded_accuracy: 0.9467 - val_loss: 0.3221 - val_rounded_accuracy: 0.9416\n",
      "Epoch 31/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3156 - rounded_accuracy: 0.9469 - val_loss: 0.3222 - val_rounded_accuracy: 0.9424\n",
      "Epoch 32/500\n",
      "5011/5011 [==============================] - 0s 97us/sample - loss: 0.3152 - rounded_accuracy: 0.9475 - val_loss: 0.3216 - val_rounded_accuracy: 0.9417\n",
      "Epoch 33/500\n",
      "5011/5011 [==============================] - 0s 98us/sample - loss: 0.3149 - rounded_accuracy: 0.9478 - val_loss: 0.3212 - val_rounded_accuracy: 0.9428\n",
      "Epoch 34/500\n",
      "5011/5011 [==============================] - 1s 100us/sample - loss: 0.3146 - rounded_accuracy: 0.9480 - val_loss: 0.3211 - val_rounded_accuracy: 0.9421\n",
      "Epoch 35/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3143 - rounded_accuracy: 0.9485 - val_loss: 0.3207 - val_rounded_accuracy: 0.9427\n",
      "Epoch 36/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3140 - rounded_accuracy: 0.9489 - val_loss: 0.3208 - val_rounded_accuracy: 0.9421\n",
      "Epoch 37/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3138 - rounded_accuracy: 0.9491 - val_loss: 0.3201 - val_rounded_accuracy: 0.9438\n",
      "Epoch 38/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3135 - rounded_accuracy: 0.9496 - val_loss: 0.3201 - val_rounded_accuracy: 0.9445\n",
      "Epoch 39/500\n",
      "5011/5011 [==============================] - 0s 95us/sample - loss: 0.3132 - rounded_accuracy: 0.9499 - val_loss: 0.3197 - val_rounded_accuracy: 0.9447\n",
      "Epoch 40/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3130 - rounded_accuracy: 0.9501 - val_loss: 0.3195 - val_rounded_accuracy: 0.9453\n",
      "Epoch 41/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3127 - rounded_accuracy: 0.9505 - val_loss: 0.3192 - val_rounded_accuracy: 0.9455\n",
      "Epoch 42/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3126 - rounded_accuracy: 0.9507 - val_loss: 0.3191 - val_rounded_accuracy: 0.9453\n",
      "Epoch 43/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3124 - rounded_accuracy: 0.9510 - val_loss: 0.3189 - val_rounded_accuracy: 0.9459\n",
      "Epoch 44/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3121 - rounded_accuracy: 0.9513 - val_loss: 0.3186 - val_rounded_accuracy: 0.9465\n",
      "Epoch 45/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3119 - rounded_accuracy: 0.9516 - val_loss: 0.3184 - val_rounded_accuracy: 0.9467\n",
      "Epoch 46/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3117 - rounded_accuracy: 0.9519 - val_loss: 0.3184 - val_rounded_accuracy: 0.9471\n",
      "Epoch 47/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3116 - rounded_accuracy: 0.9520 - val_loss: 0.3180 - val_rounded_accuracy: 0.9474\n",
      "Epoch 48/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3113 - rounded_accuracy: 0.9525 - val_loss: 0.3186 - val_rounded_accuracy: 0.9473\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3113 - rounded_accuracy: 0.9525 - val_loss: 0.3180 - val_rounded_accuracy: 0.9478\n",
      "Epoch 50/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3110 - rounded_accuracy: 0.9529 - val_loss: 0.3175 - val_rounded_accuracy: 0.9480\n",
      "Epoch 51/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3109 - rounded_accuracy: 0.9531 - val_loss: 0.3176 - val_rounded_accuracy: 0.9486\n",
      "Epoch 52/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3108 - rounded_accuracy: 0.9531 - val_loss: 0.3176 - val_rounded_accuracy: 0.9473\n",
      "Epoch 53/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3107 - rounded_accuracy: 0.9532 - val_loss: 0.3171 - val_rounded_accuracy: 0.9486\n",
      "Epoch 54/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3103 - rounded_accuracy: 0.9536 - val_loss: 0.3170 - val_rounded_accuracy: 0.9488\n",
      "Epoch 55/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3102 - rounded_accuracy: 0.9538 - val_loss: 0.3169 - val_rounded_accuracy: 0.9488\n",
      "Epoch 56/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3102 - rounded_accuracy: 0.9541 - val_loss: 0.3169 - val_rounded_accuracy: 0.9484\n",
      "Epoch 57/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3100 - rounded_accuracy: 0.9542 - val_loss: 0.3169 - val_rounded_accuracy: 0.9490\n",
      "Epoch 58/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3098 - rounded_accuracy: 0.9544 - val_loss: 0.3163 - val_rounded_accuracy: 0.9493\n",
      "Epoch 59/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3097 - rounded_accuracy: 0.9545 - val_loss: 0.3167 - val_rounded_accuracy: 0.9491\n",
      "Epoch 60/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3096 - rounded_accuracy: 0.9547 - val_loss: 0.3161 - val_rounded_accuracy: 0.9496\n",
      "Epoch 61/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3095 - rounded_accuracy: 0.9548 - val_loss: 0.3162 - val_rounded_accuracy: 0.9490\n",
      "Epoch 62/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3094 - rounded_accuracy: 0.9550 - val_loss: 0.3164 - val_rounded_accuracy: 0.9484\n",
      "Epoch 63/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3093 - rounded_accuracy: 0.9549 - val_loss: 0.3159 - val_rounded_accuracy: 0.9499\n",
      "Epoch 64/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3091 - rounded_accuracy: 0.9554 - val_loss: 0.3158 - val_rounded_accuracy: 0.9503\n",
      "Epoch 65/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3090 - rounded_accuracy: 0.9554 - val_loss: 0.3159 - val_rounded_accuracy: 0.9502\n",
      "Epoch 66/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3089 - rounded_accuracy: 0.9556 - val_loss: 0.3158 - val_rounded_accuracy: 0.9502\n",
      "Epoch 67/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3089 - rounded_accuracy: 0.9557 - val_loss: 0.3158 - val_rounded_accuracy: 0.9498\n",
      "Epoch 68/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3087 - rounded_accuracy: 0.9559 - val_loss: 0.3154 - val_rounded_accuracy: 0.9505\n",
      "Epoch 69/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3086 - rounded_accuracy: 0.9561 - val_loss: 0.3154 - val_rounded_accuracy: 0.9508\n",
      "Epoch 70/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3085 - rounded_accuracy: 0.9562 - val_loss: 0.3155 - val_rounded_accuracy: 0.9510\n",
      "Epoch 71/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3083 - rounded_accuracy: 0.9563 - val_loss: 0.3152 - val_rounded_accuracy: 0.9506\n",
      "Epoch 72/500\n",
      "5011/5011 [==============================] - 0s 88us/sample - loss: 0.3084 - rounded_accuracy: 0.9564 - val_loss: 0.3151 - val_rounded_accuracy: 0.9511\n",
      "Epoch 73/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3083 - rounded_accuracy: 0.9565 - val_loss: 0.3152 - val_rounded_accuracy: 0.9510\n",
      "Epoch 74/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3082 - rounded_accuracy: 0.9565 - val_loss: 0.3151 - val_rounded_accuracy: 0.9510\n",
      "Epoch 75/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3080 - rounded_accuracy: 0.9568 - val_loss: 0.3151 - val_rounded_accuracy: 0.9515\n",
      "Epoch 76/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3079 - rounded_accuracy: 0.9570 - val_loss: 0.3150 - val_rounded_accuracy: 0.9514\n",
      "Epoch 77/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3079 - rounded_accuracy: 0.9568 - val_loss: 0.3149 - val_rounded_accuracy: 0.9515\n",
      "Epoch 78/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3078 - rounded_accuracy: 0.9570 - val_loss: 0.3149 - val_rounded_accuracy: 0.9513\n",
      "Epoch 79/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3077 - rounded_accuracy: 0.9571 - val_loss: 0.3147 - val_rounded_accuracy: 0.9523\n",
      "Epoch 80/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3077 - rounded_accuracy: 0.9572 - val_loss: 0.3148 - val_rounded_accuracy: 0.9513\n",
      "Epoch 81/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3076 - rounded_accuracy: 0.9574 - val_loss: 0.3150 - val_rounded_accuracy: 0.9508\n",
      "Epoch 82/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3075 - rounded_accuracy: 0.9574 - val_loss: 0.3147 - val_rounded_accuracy: 0.9508\n",
      "Epoch 83/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3074 - rounded_accuracy: 0.9577 - val_loss: 0.3144 - val_rounded_accuracy: 0.9522\n",
      "Epoch 84/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3074 - rounded_accuracy: 0.9577 - val_loss: 0.3146 - val_rounded_accuracy: 0.9519\n",
      "Epoch 85/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3073 - rounded_accuracy: 0.9578 - val_loss: 0.3143 - val_rounded_accuracy: 0.9525\n",
      "Epoch 86/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3071 - rounded_accuracy: 0.9579 - val_loss: 0.3141 - val_rounded_accuracy: 0.9529\n",
      "Epoch 87/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3071 - rounded_accuracy: 0.9580 - val_loss: 0.3143 - val_rounded_accuracy: 0.9523\n",
      "Epoch 88/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3071 - rounded_accuracy: 0.9581 - val_loss: 0.3141 - val_rounded_accuracy: 0.9522\n",
      "Epoch 89/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3070 - rounded_accuracy: 0.9583 - val_loss: 0.3143 - val_rounded_accuracy: 0.9524\n",
      "Epoch 90/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3069 - rounded_accuracy: 0.9583 - val_loss: 0.3142 - val_rounded_accuracy: 0.9519\n",
      "Epoch 91/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3069 - rounded_accuracy: 0.9584 - val_loss: 0.3142 - val_rounded_accuracy: 0.9515\n",
      "Epoch 92/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3068 - rounded_accuracy: 0.9585 - val_loss: 0.3141 - val_rounded_accuracy: 0.9528\n",
      "Epoch 93/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3067 - rounded_accuracy: 0.9586 - val_loss: 0.3143 - val_rounded_accuracy: 0.9514\n",
      "Epoch 94/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3067 - rounded_accuracy: 0.9586 - val_loss: 0.3139 - val_rounded_accuracy: 0.9531\n",
      "Epoch 95/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3066 - rounded_accuracy: 0.9587 - val_loss: 0.3138 - val_rounded_accuracy: 0.9527\n",
      "Epoch 96/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3065 - rounded_accuracy: 0.9589 - val_loss: 0.3139 - val_rounded_accuracy: 0.9527\n",
      "Epoch 97/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3065 - rounded_accuracy: 0.9590 - val_loss: 0.3137 - val_rounded_accuracy: 0.9530\n",
      "Epoch 98/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3064 - rounded_accuracy: 0.9591 - val_loss: 0.3139 - val_rounded_accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3064 - rounded_accuracy: 0.9590 - val_loss: 0.3139 - val_rounded_accuracy: 0.9529\n",
      "Epoch 100/500\n",
      "5011/5011 [==============================] - 0s 98us/sample - loss: 0.3064 - rounded_accuracy: 0.9592 - val_loss: 0.3139 - val_rounded_accuracy: 0.9530\n",
      "Epoch 101/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3062 - rounded_accuracy: 0.9592 - val_loss: 0.3136 - val_rounded_accuracy: 0.9529\n",
      "Epoch 102/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3062 - rounded_accuracy: 0.9593 - val_loss: 0.3138 - val_rounded_accuracy: 0.9525\n",
      "Epoch 103/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3062 - rounded_accuracy: 0.9593 - val_loss: 0.3137 - val_rounded_accuracy: 0.9529\n",
      "Epoch 104/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3061 - rounded_accuracy: 0.9594 - val_loss: 0.3135 - val_rounded_accuracy: 0.9530\n",
      "Epoch 105/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3061 - rounded_accuracy: 0.9596 - val_loss: 0.3137 - val_rounded_accuracy: 0.9524\n",
      "Epoch 106/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3060 - rounded_accuracy: 0.9596 - val_loss: 0.3136 - val_rounded_accuracy: 0.9535\n",
      "Epoch 107/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3060 - rounded_accuracy: 0.9595 - val_loss: 0.3134 - val_rounded_accuracy: 0.9536\n",
      "Epoch 108/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3060 - rounded_accuracy: 0.9596 - val_loss: 0.3134 - val_rounded_accuracy: 0.9535\n",
      "Epoch 109/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3059 - rounded_accuracy: 0.9596 - val_loss: 0.3136 - val_rounded_accuracy: 0.9536\n",
      "Epoch 110/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3059 - rounded_accuracy: 0.9597 - val_loss: 0.3133 - val_rounded_accuracy: 0.9533\n",
      "Epoch 111/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3058 - rounded_accuracy: 0.9599 - val_loss: 0.3134 - val_rounded_accuracy: 0.9537\n",
      "Epoch 112/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3058 - rounded_accuracy: 0.9599 - val_loss: 0.3135 - val_rounded_accuracy: 0.9531\n",
      "Epoch 113/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3057 - rounded_accuracy: 0.9600 - val_loss: 0.3133 - val_rounded_accuracy: 0.9533\n",
      "Epoch 114/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3057 - rounded_accuracy: 0.9598 - val_loss: 0.3134 - val_rounded_accuracy: 0.9533\n",
      "Epoch 115/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3057 - rounded_accuracy: 0.9601 - val_loss: 0.3132 - val_rounded_accuracy: 0.9537\n",
      "Epoch 116/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3056 - rounded_accuracy: 0.9602 - val_loss: 0.3131 - val_rounded_accuracy: 0.9541\n",
      "Epoch 117/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3055 - rounded_accuracy: 0.9604 - val_loss: 0.3130 - val_rounded_accuracy: 0.9540\n",
      "Epoch 118/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3055 - rounded_accuracy: 0.9602 - val_loss: 0.3134 - val_rounded_accuracy: 0.9532\n",
      "Epoch 119/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3055 - rounded_accuracy: 0.9603 - val_loss: 0.3130 - val_rounded_accuracy: 0.9541\n",
      "Epoch 120/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3055 - rounded_accuracy: 0.9603 - val_loss: 0.3130 - val_rounded_accuracy: 0.9537\n",
      "Epoch 121/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3054 - rounded_accuracy: 0.9606 - val_loss: 0.3129 - val_rounded_accuracy: 0.9544\n",
      "Epoch 122/500\n",
      "5011/5011 [==============================] - 0s 88us/sample - loss: 0.3053 - rounded_accuracy: 0.9607 - val_loss: 0.3131 - val_rounded_accuracy: 0.9542\n",
      "Epoch 123/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3053 - rounded_accuracy: 0.9605 - val_loss: 0.3131 - val_rounded_accuracy: 0.9535\n",
      "Epoch 124/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3053 - rounded_accuracy: 0.9606 - val_loss: 0.3128 - val_rounded_accuracy: 0.9543\n",
      "Epoch 125/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3053 - rounded_accuracy: 0.9607 - val_loss: 0.3129 - val_rounded_accuracy: 0.9542\n",
      "Epoch 126/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3052 - rounded_accuracy: 0.9607 - val_loss: 0.3129 - val_rounded_accuracy: 0.9542\n",
      "Epoch 127/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3052 - rounded_accuracy: 0.9608 - val_loss: 0.3129 - val_rounded_accuracy: 0.9544\n",
      "Epoch 128/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3052 - rounded_accuracy: 0.9608 - val_loss: 0.3128 - val_rounded_accuracy: 0.9544\n",
      "Epoch 129/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3051 - rounded_accuracy: 0.9609 - val_loss: 0.3131 - val_rounded_accuracy: 0.9538\n",
      "Epoch 130/500\n",
      "5011/5011 [==============================] - 0s 88us/sample - loss: 0.3051 - rounded_accuracy: 0.9609 - val_loss: 0.3127 - val_rounded_accuracy: 0.9542\n",
      "Epoch 131/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3052 - rounded_accuracy: 0.9608 - val_loss: 0.3130 - val_rounded_accuracy: 0.9537\n",
      "Epoch 132/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3050 - rounded_accuracy: 0.9611 - val_loss: 0.3127 - val_rounded_accuracy: 0.9541\n",
      "Epoch 133/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3050 - rounded_accuracy: 0.9610 - val_loss: 0.3127 - val_rounded_accuracy: 0.9542\n",
      "Epoch 134/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3049 - rounded_accuracy: 0.9611 - val_loss: 0.3127 - val_rounded_accuracy: 0.9549\n",
      "Epoch 135/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3049 - rounded_accuracy: 0.9611 - val_loss: 0.3128 - val_rounded_accuracy: 0.9542\n",
      "Epoch 136/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3049 - rounded_accuracy: 0.9611 - val_loss: 0.3126 - val_rounded_accuracy: 0.9541\n",
      "Epoch 137/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3049 - rounded_accuracy: 0.9612 - val_loss: 0.3128 - val_rounded_accuracy: 0.9546\n",
      "Epoch 138/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3048 - rounded_accuracy: 0.9613 - val_loss: 0.3127 - val_rounded_accuracy: 0.9545\n",
      "Epoch 139/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3048 - rounded_accuracy: 0.9613 - val_loss: 0.3129 - val_rounded_accuracy: 0.9533\n",
      "Epoch 140/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3048 - rounded_accuracy: 0.9612 - val_loss: 0.3129 - val_rounded_accuracy: 0.9544\n",
      "Epoch 141/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3047 - rounded_accuracy: 0.9614 - val_loss: 0.3125 - val_rounded_accuracy: 0.9551\n",
      "Epoch 142/500\n",
      "5011/5011 [==============================] - 0s 93us/sample - loss: 0.3047 - rounded_accuracy: 0.9614 - val_loss: 0.3127 - val_rounded_accuracy: 0.9547\n",
      "Epoch 143/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3046 - rounded_accuracy: 0.9615 - val_loss: 0.3126 - val_rounded_accuracy: 0.9548\n",
      "Epoch 144/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3048 - rounded_accuracy: 0.9615 - val_loss: 0.3124 - val_rounded_accuracy: 0.9551\n",
      "Epoch 145/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3047 - rounded_accuracy: 0.9616 - val_loss: 0.3125 - val_rounded_accuracy: 0.9552\n",
      "Epoch 146/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3047 - rounded_accuracy: 0.9615 - val_loss: 0.3125 - val_rounded_accuracy: 0.9548\n",
      "Epoch 147/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3045 - rounded_accuracy: 0.9618 - val_loss: 0.3125 - val_rounded_accuracy: 0.9551\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3046 - rounded_accuracy: 0.9617 - val_loss: 0.3125 - val_rounded_accuracy: 0.9544\n",
      "Epoch 149/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3046 - rounded_accuracy: 0.9616 - val_loss: 0.3124 - val_rounded_accuracy: 0.9553\n",
      "Epoch 150/500\n",
      "5011/5011 [==============================] - 0s 96us/sample - loss: 0.3045 - rounded_accuracy: 0.9618 - val_loss: 0.3126 - val_rounded_accuracy: 0.9549\n",
      "Epoch 151/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3045 - rounded_accuracy: 0.9617 - val_loss: 0.3123 - val_rounded_accuracy: 0.9551\n",
      "Epoch 152/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3044 - rounded_accuracy: 0.9619 - val_loss: 0.3124 - val_rounded_accuracy: 0.9551\n",
      "Epoch 153/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3044 - rounded_accuracy: 0.9619 - val_loss: 0.3124 - val_rounded_accuracy: 0.9551\n",
      "Epoch 154/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3044 - rounded_accuracy: 0.9619 - val_loss: 0.3124 - val_rounded_accuracy: 0.9552\n",
      "Epoch 155/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3044 - rounded_accuracy: 0.9619 - val_loss: 0.3125 - val_rounded_accuracy: 0.9555\n",
      "Epoch 156/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3044 - rounded_accuracy: 0.9620 - val_loss: 0.3124 - val_rounded_accuracy: 0.9553\n",
      "Epoch 157/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3043 - rounded_accuracy: 0.9620 - val_loss: 0.3123 - val_rounded_accuracy: 0.9552\n",
      "Epoch 158/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3043 - rounded_accuracy: 0.9620 - val_loss: 0.3124 - val_rounded_accuracy: 0.9551\n",
      "Epoch 159/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3044 - rounded_accuracy: 0.9619 - val_loss: 0.3126 - val_rounded_accuracy: 0.9546\n",
      "Epoch 160/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3043 - rounded_accuracy: 0.9621 - val_loss: 0.3123 - val_rounded_accuracy: 0.9545\n",
      "Epoch 161/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3043 - rounded_accuracy: 0.9621 - val_loss: 0.3122 - val_rounded_accuracy: 0.9554\n",
      "Epoch 162/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3043 - rounded_accuracy: 0.9622 - val_loss: 0.3122 - val_rounded_accuracy: 0.9551\n",
      "Epoch 163/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3043 - rounded_accuracy: 0.9620 - val_loss: 0.3122 - val_rounded_accuracy: 0.9556\n",
      "Epoch 164/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3043 - rounded_accuracy: 0.9623 - val_loss: 0.3122 - val_rounded_accuracy: 0.9549\n",
      "Epoch 165/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3042 - rounded_accuracy: 0.9622 - val_loss: 0.3121 - val_rounded_accuracy: 0.9556\n",
      "Epoch 166/500\n",
      "5011/5011 [==============================] - 0s 98us/sample - loss: 0.3041 - rounded_accuracy: 0.9623 - val_loss: 0.3122 - val_rounded_accuracy: 0.9559\n",
      "Epoch 167/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3041 - rounded_accuracy: 0.9623 - val_loss: 0.3122 - val_rounded_accuracy: 0.9556\n",
      "Epoch 168/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3042 - rounded_accuracy: 0.9623 - val_loss: 0.3121 - val_rounded_accuracy: 0.9556\n",
      "Epoch 169/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3042 - rounded_accuracy: 0.9621 - val_loss: 0.3122 - val_rounded_accuracy: 0.9554\n",
      "Epoch 170/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3041 - rounded_accuracy: 0.9623 - val_loss: 0.3123 - val_rounded_accuracy: 0.9552\n",
      "Epoch 171/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3041 - rounded_accuracy: 0.9623 - val_loss: 0.3120 - val_rounded_accuracy: 0.9557\n",
      "Epoch 172/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3040 - rounded_accuracy: 0.9626 - val_loss: 0.3122 - val_rounded_accuracy: 0.9556\n",
      "Epoch 173/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3040 - rounded_accuracy: 0.9625 - val_loss: 0.3120 - val_rounded_accuracy: 0.9556\n",
      "Epoch 174/500\n",
      "5011/5011 [==============================] - 0s 89us/sample - loss: 0.3040 - rounded_accuracy: 0.9625 - val_loss: 0.3121 - val_rounded_accuracy: 0.9559\n",
      "Epoch 175/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3040 - rounded_accuracy: 0.9625 - val_loss: 0.3123 - val_rounded_accuracy: 0.9553\n",
      "Epoch 176/500\n",
      "5011/5011 [==============================] - 0s 92us/sample - loss: 0.3040 - rounded_accuracy: 0.9627 - val_loss: 0.3122 - val_rounded_accuracy: 0.9553\n",
      "Epoch 177/500\n",
      "5011/5011 [==============================] - 0s 91us/sample - loss: 0.3040 - rounded_accuracy: 0.9626 - val_loss: 0.3123 - val_rounded_accuracy: 0.9556\n",
      "Epoch 178/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3040 - rounded_accuracy: 0.9625 - val_loss: 0.3123 - val_rounded_accuracy: 0.9550\n",
      "Epoch 179/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3040 - rounded_accuracy: 0.9626 - val_loss: 0.3121 - val_rounded_accuracy: 0.9563\n",
      "Epoch 180/500\n",
      "5011/5011 [==============================] - 0s 90us/sample - loss: 0.3040 - rounded_accuracy: 0.9625 - val_loss: 0.3122 - val_rounded_accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "sparse_kl_ae = sparse_kl_model(X_train_slim, X_val_slim, seed=42, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2250x450 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a random number of items\n",
    "import random\n",
    "index_list = random.sample(range(0,len(X_val_slim)), 10)\n",
    "\n",
    "plot_reconstructions(sparse_kl_ae, index_list, X_val_slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectThreshold:\n",
    "    \n",
    "    def __init__(self, model, X_val, y_val, X_val_slim, class_to_remove, class_normal, class_names):\n",
    "        \n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_val_slim = X_val_slim\n",
    "        self.class_to_remove = class_to_remove\n",
    "        self.class_normal = class_normal\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        print(np.shape(self.X_val))\n",
    "        \n",
    "        # build the reconstructions on the X_val_slim dataset, and the X_val dataset\n",
    "        self.recon_val_slim = self.model(self.X_val_slim).numpy()\n",
    "        self.recon_val = self.model(self.X_val).numpy()\n",
    "        \n",
    "    def mse(self, X_val, recon_val):\n",
    "        \"\"\"Calculate MSE for images in X_val and recon_val\"\"\"\n",
    "        # need to calculate mean across the rows, and then across the columns\n",
    "        return np.mean(np.mean(np.square(X_val - recon_val),axis=1),axis=1)\n",
    "\n",
    "    def rmse(self, X_val, recon_val):\n",
    "        \"\"\"Calculate RMSE for images in X_val and recon_val\"\"\"\n",
    "        return np.sqrt(self.mse(X_val, recon_val))\n",
    "\n",
    "    def euclidean_distance(self, X_val, recon_val):\n",
    "        dist = np.linalg.norm(X_val - recon_val,axis=(1,2))\n",
    "        return dist\n",
    "    \n",
    "    # function that creates a pandas dataframe with the RMSE value, and the associated class\n",
    "    def create_df_reconstruction(self, reconstruction_error_val, threshold_val):\n",
    "        df = pd.DataFrame(data=reconstruction_error_val, columns=[\"metric\"])\n",
    "\n",
    "        class_names_list = list(zip(self.class_names, range(len(self.class_names))))\n",
    "        \n",
    "        y_names = []\n",
    "        for i in self.y_val:\n",
    "            y_names.append(str(i)+\", \"+class_names_list[i][0])\n",
    "        \n",
    "        # append the class values\n",
    "        df['class'] = self.y_val\n",
    "        df['class_names'] = y_names\n",
    "\n",
    "        # label anomolous (outlier) data as -1, inliers as 1\n",
    "            # -1 (outlier) is POSITIVE class\n",
    "            #  1 (inlier) is NEGATIVE class\n",
    "        new_y_val = []\n",
    "        for i in self.y_val:\n",
    "            if i in class_to_remove:\n",
    "                new_y_val.append(-1)\n",
    "            else:\n",
    "                new_y_val.append(1)\n",
    "\n",
    "        df['true_class'] = new_y_val\n",
    "\n",
    "        # add prediction based on threshold\n",
    "        df['prediction'] = np.where(df['metric'] >= threshold_val,-1,1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def threshold_grid_search(self, lower_bound, upper_bound, reconstruction_error_val, grid_iterations=10):\n",
    "        '''Simple grid search for finding the best threshold'''\n",
    "    \n",
    "        roc_scores = {}\n",
    "        grid_search_count = 0\n",
    "        for i in np.arange(lower_bound, upper_bound, (np.abs(upper_bound-lower_bound) / grid_iterations)):\n",
    "#             if grid_search_count%50 == 0:\n",
    "#                 print('grid search iteration: ', grid_search_count)\n",
    "\n",
    "            threshold_val = i\n",
    "            df = self.create_df_reconstruction(reconstruction_error_val, \n",
    "                                          threshold_val)\n",
    "            roc_val = roc_auc_score(df['true_class'], df['prediction'])\n",
    "            roc_scores[i] = roc_val\n",
    "            grid_search_count += 1\n",
    "\n",
    "        # return best roc_score and the threshold used to set it\n",
    "        threshold_val = max(zip(roc_scores.values(), roc_scores.keys()))\n",
    "        best_threshold = threshold_val[1]\n",
    "        best_roc_score = threshold_val[0]\n",
    "        print('Best threshold value:', best_threshold,'\\tROC score: {:.2%}'.format(best_roc_score))\n",
    "\n",
    "        # use the best threshold value to make a confusion matrix\n",
    "        df = self.create_df_reconstruction(reconstruction_error_val, best_threshold)\n",
    "        \n",
    "        return df, best_threshold, best_roc_score\n",
    "    \n",
    "    def box_plot(self, df, best_threshold, best_roc_score, metric):\n",
    "        fig, ax = plt.subplots(figsize=(12,5))\n",
    "        df.boxplot(column=['metric'], by='class_names', ax=ax).axhline(y=best_threshold,c='red',alpha=0.7)\n",
    "        plt.title('Boxplots of {} for X_valid, by Class'.format(metric))\n",
    "        plt.suptitle('')\n",
    "        plt.show()\n",
    "        \n",
    "#         print('\\nConfusion Matrix:')\n",
    "#         print(confusion_matrix(df['true_class'], df['prediction']))\n",
    "        \n",
    "    # function to test the different reconstruction methods (mse, rmse, euclidean)\n",
    "    # do a grid search looking for the best threshold, and then outputting the results\n",
    "    def compare_error_method(self,show_results=True, grid_iterations=10):\n",
    "        '''Function to test the different reconstruction methods (mse, rmse, euclidean) \n",
    "\n",
    "        Parameters\n",
    "        ===========\n",
    "        model : tensorflow model\n",
    "            autoencoder model that was trained on the \"slim\" data set.\n",
    "            Will be used to build reconstructions\n",
    "\n",
    "        X_val : ndarray\n",
    "            tensor of the X validation set\n",
    "\n",
    "        class_to_remove : ndarray\n",
    "            numpy array of the classes to remove from the X_val and y_val data\n",
    "        '''\n",
    "        \n",
    "        col = ['class_normal','method','best_threshold','best_roc_score']\n",
    "        result_table = pd.DataFrame(columns=col)\n",
    "        \n",
    "        # build the reconstructions on the X_val_slim dataset, and the X_val dataset\n",
    "        recon_val_slim = self.model(self.X_val_slim).numpy()\n",
    "        recon_val = self.model(self.X_val).numpy()\n",
    "\n",
    "        # run through each of the reconstruction error methods, perform a little grid search\n",
    "        # to find the optimum value\n",
    "\n",
    "        #_______MSE_______#\n",
    "        # calculate MSE reconstruction error\n",
    "        mse_recon_val_slim = self.mse(self.X_val_slim, recon_val_slim) # for slim dataset\n",
    "        mse_recon_val = self.mse(self.X_val, recon_val) # for complete validation dataset\n",
    "        \n",
    "        max_mse = np.max(mse_recon_val_slim)\n",
    "        percentile_mse = np.percentile(mse_recon_val_slim,90)\n",
    "#         print('Max MSE on val_slim:\\t\\t\\t',max_mse)\n",
    "#         print('90th MSE percentile on val_slim:\\t', percentile_mse)\n",
    "\n",
    "        lower_bound = percentile_mse - percentile_mse*0.9\n",
    "        upper_bound = max_mse*1.5\n",
    "\n",
    "        df, best_threshold, best_roc_score = self.threshold_grid_search(lower_bound,\n",
    "                                                                                upper_bound,\n",
    "                                                                                mse_recon_val,grid_iterations)\n",
    "        result_table = result_table.append(pd.DataFrame([[self.class_normal,'mse',\n",
    "                                                          best_threshold, \n",
    "                                                          best_roc_score]],\n",
    "                                                        columns=col))\n",
    "        \n",
    "        if show_results == True:\n",
    "            self.box_plot(df, best_threshold, best_roc_score, 'MSE')\n",
    "        \n",
    "        #_______RMSE_______#\n",
    "        # calculate RMSE reconstruction error\n",
    "        rmse_recon_val_slim = self.rmse(self.X_val_slim, recon_val_slim) # for slim dataset\n",
    "        rmse_recon_val = self.rmse(self.X_val, recon_val) # for complete validation dataset\n",
    "        \n",
    "        max_rmse = np.max(rmse_recon_val_slim)\n",
    "        percentile_rmse = np.percentile(rmse_recon_val_slim,90)\n",
    "#         print('Max RMSE on val_slim:\\t\\t\\t',max_rmse)\n",
    "#         print('90th RMSE percentile on val_slim:\\t', percentile_rmse)\n",
    "\n",
    "        lower_bound = percentile_rmse - percentile_rmse*0.9\n",
    "        upper_bound = max_rmse*1.5\n",
    "\n",
    "        df, best_threshold, best_roc_score = self.threshold_grid_search(lower_bound,\n",
    "                                                                                upper_bound,\n",
    "                                                                                rmse_recon_val,grid_iterations)\n",
    "        \n",
    "        result_table = result_table.append(pd.DataFrame([[self.class_normal,'rmse',\n",
    "                                                  best_threshold, \n",
    "                                                  best_roc_score]],\n",
    "                                                columns=col))\n",
    "        \n",
    "        if show_results == True:\n",
    "            self.box_plot(df, best_threshold, best_roc_score, 'RMSE')\n",
    "        \n",
    "        #_______Euclidean_______#\n",
    "        # calculate Euclidean reconstruction error\n",
    "        eu_recon_val_slim = self.euclidean_distance(self.X_val_slim, recon_val_slim) # for slim dataset\n",
    "        eu_recon_val = self.euclidean_distance(self.X_val, recon_val) # for complete validation dataset\n",
    "        \n",
    "        max_eu = np.max(eu_recon_val_slim)\n",
    "        percentile_eu = np.percentile(eu_recon_val_slim,90)\n",
    "#         print('Max Euc. on val_slim:\\t\\t\\t',max_eu)\n",
    "#         print('90th Euc. percentile on val_slim:\\t', percentile_eu)\n",
    "\n",
    "        lower_bound = percentile_eu - percentile_eu*0.9\n",
    "        upper_bound = max_eu*1.5\n",
    "\n",
    "        df, best_threshold, best_roc_score = self.threshold_grid_search(lower_bound,\n",
    "                                                                      upper_bound, \n",
    "                                                                      eu_recon_val,grid_iterations)\n",
    "        \n",
    "        result_table = result_table.append(pd.DataFrame([[self.class_normal,'euclid_dist',\n",
    "                                          best_threshold, \n",
    "                                          best_roc_score]],\n",
    "                                        columns=col))\n",
    "        if show_results == True:\n",
    "            self.box_plot(df, best_threshold, best_roc_score, 'Euclidean Distance')\n",
    "        \n",
    "        return result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "class_to_remove = [i for i in range(0,10)]\n",
    "class_to_remove.remove(class_normal)\n",
    "class_to_remove = np.array(class_to_remove,dtype='uint8')\n",
    "\n",
    "model = SelectThreshold(sparse_kl_ae, X_val, y_val, X_val_slim, class_to_remove, class_normal, class_names)\n",
    "# model = SelectThreshold(sparse_kl_ae, X_train, y_train, X_train_slim, class_to_remove, class_normal, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold value: 0.006637242125859484 \tROC score: 84.16%\n",
      "Best threshold value: 0.08192944648303088 \tROC score: 84.20%\n",
      "Best threshold value: 2.2940245608091363 \tROC score: 84.20%\n"
     ]
    }
   ],
   "source": [
    "df = model.compare_error_method(show_results=False, grid_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_normal</th>\n",
       "      <th>method</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>best_roc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.865276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.087005</td>\n",
       "      <td>0.865346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>2.436133</td>\n",
       "      <td>0.865346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_normal       method  best_threshold  best_roc_score\n",
       "0            0          mse        0.007413        0.865276\n",
       "0            0         rmse        0.087005        0.865346\n",
       "0            0  euclid_dist        2.436133        0.865346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Multiple Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run no:  1\n",
      "Random seed:  225\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4f014278>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08259250391274692 \tROC score: 65.37%\n",
      "Best threshold value: 0.25588524967432025 \tROC score: 72.32%\n",
      "Best threshold value: 7.164786968231201 \tROC score: 72.32%\n",
      "Run no:  2\n",
      "Random seed:  28\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4f55b278>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.12584236906841395 \tROC score: 54.15%\n",
      "Best threshold value: 0.3149316623806953 \tROC score: 59.99%\n",
      "Best threshold value: 8.818085670471191 \tROC score: 59.99%\n",
      "Run no:  3\n",
      "Random seed:  173\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4f55b518>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08753055954352021 \tROC score: 71.82%\n",
      "Best threshold value: 0.2625706380605698 \tROC score: 79.02%\n",
      "Best threshold value: 7.351978311538696 \tROC score: 79.02%\n",
      "Run no:  4\n",
      "Random seed:  224\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b5aca3e10>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.07247426956892013 \tROC score: 78.35%\n",
      "Best threshold value: 0.23924508713185785 \tROC score: 84.45%\n",
      "Best threshold value: 6.698862521648407 \tROC score: 84.45%\n",
      "Run no:  5\n",
      "Random seed:  108\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b5acd3da0>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08495176941156388 \tROC score: 66.03%\n",
      "Best threshold value: 0.2597336173057556 \tROC score: 72.90%\n",
      "Best threshold value: 7.272541096210479 \tROC score: 72.90%\n",
      "Run no:  6\n",
      "Random seed:  123\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4de05e48>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.09617184529080987 \tROC score: 62.75%\n",
      "Best threshold value: 0.27611754707992076 \tROC score: 69.90%\n",
      "Best threshold value: 7.731291403770446 \tROC score: 69.90%\n",
      "Run no:  7\n",
      "Random seed:  53\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b5b2dbc18>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.06930995617061853 \tROC score: 71.49%\n",
      "Best threshold value: 0.234524514824152 \tROC score: 76.37%\n",
      "Best threshold value: 6.566686415672302 \tROC score: 76.37%\n",
      "Run no:  8\n",
      "Random seed:  144\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4f3150f0>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.07726262010633946 \tROC score: 69.04%\n",
      "Best threshold value: 0.24745396792888644 \tROC score: 74.46%\n",
      "Best threshold value: 6.928710670471191 \tROC score: 74.46%\n",
      "Run no:  9\n",
      "Random seed:  35\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b5013eba8>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.1291641725227237 \tROC score: 54.19%\n",
      "Best threshold value: 0.3185466499626637 \tROC score: 59.54%\n",
      "Best threshold value: 8.919306268692015 \tROC score: 59.54%\n",
      "Run no:  10\n",
      "Random seed:  49\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4dbd3320>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.07261896777898072 \tROC score: 67.08%\n",
      "Best threshold value: 0.23998133018612863 \tROC score: 74.50%\n",
      "Best threshold value: 6.719477248191834 \tROC score: 74.50%\n",
      "Run no:  11\n",
      "Random seed:  21\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4daed278>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.09152750998735429 \tROC score: 74.01%\n",
      "Best threshold value: 0.26986713662743567 \tROC score: 78.16%\n",
      "Best threshold value: 7.556280641555786 \tROC score: 78.16%\n",
      "Run no:  12\n",
      "Random seed:  245\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b520ad518>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08482073530554772 \tROC score: 74.41%\n",
      "Best threshold value: 0.2598932267725468 \tROC score: 77.14%\n",
      "Best threshold value: 7.277010431289672 \tROC score: 77.14%\n",
      "Run no:  13\n",
      "Random seed:  147\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4fe1b550>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.07331465270370244 \tROC score: 63.99%\n",
      "Best threshold value: 0.24136352315545082 \tROC score: 68.40%\n",
      "Best threshold value: 6.758179268836975 \tROC score: 68.40%\n",
      "Run no:  14\n",
      "Random seed:  199\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4e92f470>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08694968819618226 \tROC score: 60.91%\n",
      "Best threshold value: 0.2625611811876297 \tROC score: 65.06%\n",
      "Best threshold value: 7.351712453365326 \tROC score: 65.06%\n",
      "Run no:  15\n",
      "Random seed:  177\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6a88583b00>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.04804262238554656 \tROC score: 91.18%\n",
      "Best threshold value: 0.19542437702417373 \tROC score: 92.52%\n",
      "Best threshold value: 5.471882276535034 \tROC score: 92.52%\n",
      "Run no:  16\n",
      "Random seed:  230\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4d6028d0>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.05441592296585441 \tROC score: 90.25%\n",
      "Best threshold value: 0.20781681567430496 \tROC score: 91.94%\n",
      "Best threshold value: 5.818870663642883 \tROC score: 91.94%\n",
      "Run no:  17\n",
      "Random seed:  164\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6a886b95f8>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.08850526772439479 \tROC score: 56.64%\n",
      "Best threshold value: 0.26495950631797316 \tROC score: 63.47%\n",
      "Best threshold value: 7.418866348266602 \tROC score: 63.47%\n",
      "Run no:  18\n",
      "Random seed:  114\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6a88083358>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.06379302345216274 \tROC score: 63.87%\n",
      "Best threshold value: 0.22557351067662237 \tROC score: 70.05%\n",
      "Best threshold value: 6.316058301925659 \tROC score: 70.05%\n",
      "Run no:  19\n",
      "Random seed:  107\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6b4fc3bb38>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.06674132520332932 \tROC score: 80.14%\n",
      "Best threshold value: 0.23021410167217254 \tROC score: 84.43%\n",
      "Best threshold value: 6.445994772911072 \tROC score: 84.43%\n",
      "Run no:  20\n",
      "Random seed:  174\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDivergenceRegularizer object at 0x7f6ab0776f60>)\n",
      "(5000, 28, 28)\n",
      "Best threshold value: 0.07003764931112529 \tROC score: 81.75%\n",
      "Best threshold value: 0.23588097251951692 \tROC score: 87.02%\n",
      "Best threshold value: 6.604666612148285 \tROC score: 87.02%\n"
     ]
    }
   ],
   "source": [
    "col = ['class_normal','method','best_threshold','best_roc_score']\n",
    "df_all = pd.DataFrame(columns=col)\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "run_no = 1\n",
    "for class_normal in range(0,10):\n",
    "    for i in range(0,20):\n",
    "        print('Run no: ', run_no)\n",
    "        # load data\n",
    "    #     class_normal = 0\n",
    "\n",
    "        # class names\n",
    "        class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                       \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "        random_int = random.randint(0,250)\n",
    "        print('Random seed: ',random_int)\n",
    "        \n",
    "        data_model = DataPrep(fashion_mnist,class_normal, random_int=random_int)\n",
    "\n",
    "        (X_train, y_train, \n",
    "         X_train_slim, y_train_slim,\n",
    "         X_val, y_val,\n",
    "         X_val_slim, y_val_slim,\n",
    "         X_test,y_test) = data_model.train_test_split()\n",
    "\n",
    "        sparse_kl_ae = sparse_kl_model(X_train_slim, X_val_slim, seed=random_int, epochs=500, earlystop_patience=6)\n",
    "\n",
    "        class_to_remove = [i for i in range(0,10)]\n",
    "        class_to_remove.remove(class_normal)\n",
    "        class_to_remove = np.array(class_to_remove,dtype='uint8')\n",
    "\n",
    "        model = SelectThreshold(sparse_kl_ae, X_val, y_val, X_val_slim, class_to_remove, class_normal, class_names)\n",
    "        df = model.compare_error_method(show_results=False, grid_iterations=200)\n",
    "\n",
    "        df_all = df_all.append(df)\n",
    "        \n",
    "        run_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_normal</th>\n",
       "      <th>method</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>best_roc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>0.653677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.255885</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.164787</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.125842</td>\n",
       "      <td>0.541534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.314932</td>\n",
       "      <td>0.599904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>8.818086</td>\n",
       "      <td>0.599904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.087531</td>\n",
       "      <td>0.718236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.262571</td>\n",
       "      <td>0.790187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.351978</td>\n",
       "      <td>0.790187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.072474</td>\n",
       "      <td>0.783540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.239245</td>\n",
       "      <td>0.844527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.698863</td>\n",
       "      <td>0.844527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.084952</td>\n",
       "      <td>0.660293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.259734</td>\n",
       "      <td>0.728979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.272541</td>\n",
       "      <td>0.728979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.096172</td>\n",
       "      <td>0.627509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.276118</td>\n",
       "      <td>0.699022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.731291</td>\n",
       "      <td>0.699022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.069310</td>\n",
       "      <td>0.714933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.234525</td>\n",
       "      <td>0.763724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.566686</td>\n",
       "      <td>0.763724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>0.690376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.247454</td>\n",
       "      <td>0.744571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.928711</td>\n",
       "      <td>0.744571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.129164</td>\n",
       "      <td>0.541871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.318547</td>\n",
       "      <td>0.595434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>8.919306</td>\n",
       "      <td>0.595434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.072619</td>\n",
       "      <td>0.670788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0.745031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.719477</td>\n",
       "      <td>0.745031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.091528</td>\n",
       "      <td>0.740076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.269867</td>\n",
       "      <td>0.781595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.556281</td>\n",
       "      <td>0.781595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.084821</td>\n",
       "      <td>0.744086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.259893</td>\n",
       "      <td>0.771428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.277010</td>\n",
       "      <td>0.771428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.073315</td>\n",
       "      <td>0.639863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.241364</td>\n",
       "      <td>0.683986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.758179</td>\n",
       "      <td>0.683986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.086950</td>\n",
       "      <td>0.609128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.650604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.351712</td>\n",
       "      <td>0.650604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>0.911838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.195424</td>\n",
       "      <td>0.925179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>5.471882</td>\n",
       "      <td>0.925179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.054416</td>\n",
       "      <td>0.902542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.207817</td>\n",
       "      <td>0.919441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>5.818871</td>\n",
       "      <td>0.919441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.088505</td>\n",
       "      <td>0.566416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.264960</td>\n",
       "      <td>0.634728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>7.418866</td>\n",
       "      <td>0.634728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.063793</td>\n",
       "      <td>0.638740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.225574</td>\n",
       "      <td>0.700525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.316058</td>\n",
       "      <td>0.700525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.066741</td>\n",
       "      <td>0.801433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.230214</td>\n",
       "      <td>0.844281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.445995</td>\n",
       "      <td>0.844281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.070038</td>\n",
       "      <td>0.817518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.235881</td>\n",
       "      <td>0.870180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>euclid_dist</td>\n",
       "      <td>6.604667</td>\n",
       "      <td>0.870180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_normal       method  best_threshold  best_roc_score\n",
       "0            0          mse        0.082593        0.653677\n",
       "0            0         rmse        0.255885        0.723232\n",
       "0            0  euclid_dist        7.164787        0.723232\n",
       "0            0          mse        0.125842        0.541534\n",
       "0            0         rmse        0.314932        0.599904\n",
       "0            0  euclid_dist        8.818086        0.599904\n",
       "0            1          mse        0.087531        0.718236\n",
       "0            1         rmse        0.262571        0.790187\n",
       "0            1  euclid_dist        7.351978        0.790187\n",
       "0            1          mse        0.072474        0.783540\n",
       "0            1         rmse        0.239245        0.844527\n",
       "0            1  euclid_dist        6.698863        0.844527\n",
       "0            2          mse        0.084952        0.660293\n",
       "0            2         rmse        0.259734        0.728979\n",
       "0            2  euclid_dist        7.272541        0.728979\n",
       "0            2          mse        0.096172        0.627509\n",
       "0            2         rmse        0.276118        0.699022\n",
       "0            2  euclid_dist        7.731291        0.699022\n",
       "0            3          mse        0.069310        0.714933\n",
       "0            3         rmse        0.234525        0.763724\n",
       "0            3  euclid_dist        6.566686        0.763724\n",
       "0            3          mse        0.077263        0.690376\n",
       "0            3         rmse        0.247454        0.744571\n",
       "0            3  euclid_dist        6.928711        0.744571\n",
       "0            4          mse        0.129164        0.541871\n",
       "0            4         rmse        0.318547        0.595434\n",
       "0            4  euclid_dist        8.919306        0.595434\n",
       "0            4          mse        0.072619        0.670788\n",
       "0            4         rmse        0.239981        0.745031\n",
       "0            4  euclid_dist        6.719477        0.745031\n",
       "0            5          mse        0.091528        0.740076\n",
       "0            5         rmse        0.269867        0.781595\n",
       "0            5  euclid_dist        7.556281        0.781595\n",
       "0            5          mse        0.084821        0.744086\n",
       "0            5         rmse        0.259893        0.771428\n",
       "0            5  euclid_dist        7.277010        0.771428\n",
       "0            6          mse        0.073315        0.639863\n",
       "0            6         rmse        0.241364        0.683986\n",
       "0            6  euclid_dist        6.758179        0.683986\n",
       "0            6          mse        0.086950        0.609128\n",
       "0            6         rmse        0.262561        0.650604\n",
       "0            6  euclid_dist        7.351712        0.650604\n",
       "0            7          mse        0.048043        0.911838\n",
       "0            7         rmse        0.195424        0.925179\n",
       "0            7  euclid_dist        5.471882        0.925179\n",
       "0            7          mse        0.054416        0.902542\n",
       "0            7         rmse        0.207817        0.919441\n",
       "0            7  euclid_dist        5.818871        0.919441\n",
       "0            8          mse        0.088505        0.566416\n",
       "0            8         rmse        0.264960        0.634728\n",
       "0            8  euclid_dist        7.418866        0.634728\n",
       "0            8          mse        0.063793        0.638740\n",
       "0            8         rmse        0.225574        0.700525\n",
       "0            8  euclid_dist        6.316058        0.700525\n",
       "0            9          mse        0.066741        0.801433\n",
       "0            9         rmse        0.230214        0.844281\n",
       "0            9  euclid_dist        6.445995        0.844281\n",
       "0            9          mse        0.070038        0.817518\n",
       "0            9         rmse        0.235881        0.870180\n",
       "0            9  euclid_dist        6.604667        0.870180"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
